{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Basic Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs = [('learn', 'learning'), ('india', 'indian'), ('fame', 'famous')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"apartment\"\n",
    "user = \"condo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GloVe Pretrained Vector Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.downloader import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'learn' and 'learning' using GloVe: 0.802\n",
      "Similarity between 'india' and 'indian' using GloVe: 0.865\n",
      "Similarity between 'fame' and 'famous' using GloVe: 0.589\n"
     ]
    }
   ],
   "source": [
    "glove_model = load('glove-wiki-gigaword-50')\n",
    " \n",
    "# Compute similarity for each pair of words\n",
    "for pair in word_pairs:\n",
    "    similarity = glove_model.similarity(pair[0], pair[1])\n",
    "    print(f\"Similarity between '{pair[0]}' and '{pair[1]}' using GloVe: {similarity:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'apartment' and 'condo' using GloVe: 0.741\n"
     ]
    }
   ],
   "source": [
    "similarity = glove_model.similarity(target, user)\n",
    "print(f\"Similarity between '{target}' and '{user}' using GloVe: {similarity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrained BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskleinknecht/Desktop/CAPSTONE/Clinical-Clarity/server/cc-venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    " \n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'learn' and 'learning' using BERT: 0.930\n",
      "Similarity between 'india' and 'indian' using BERT: 0.957\n",
      "Similarity between 'fame' and 'famous' using BERT: 0.956\n"
     ]
    }
   ],
   "source": [
    "for pair in word_pairs:\n",
    "    tokens = tokenizer(pair, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "     \n",
    "    # Extract embeddings for the [CLS] token\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    " \n",
    "    similarity = torch.nn.functional.cosine_similarity(cls_embedding[0], cls_embedding[1], dim=0)\n",
    "     \n",
    "    print(f\"Similarity between '{pair[0]}' and '{pair[1]}' using BERT: {similarity:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'apartment' and 'condo' using BERT: 0.984\n"
     ]
    }
   ],
   "source": [
    "#target = \"apa\"\n",
    "#user = \"instructor\"\n",
    "\n",
    "tokens = tokenizer((target, user), return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokens)\n",
    "    \n",
    "# Extract embeddings for the [CLS] token\n",
    "cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "similarity = torch.nn.functional.cosine_similarity(cls_embedding[0], cls_embedding[1], dim=0)\n",
    "    \n",
    "print(f\"Similarity between '{target}' and '{user}' using BERT: {similarity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sentence: Are you on any blood thinning medications?\n",
      "\n",
      "Do you take any supplements or medications?\n",
      "Similarity Score = 0.6106548491315501 \n",
      "\n",
      "How are you feeling?\n",
      "Similarity Score = 0.23295672830552505 \n",
      "\n",
      "You should do jumping jacks for the pain.\n",
      "Similarity Score = 0.08043158294056607 \n"
     ]
    }
   ],
   "source": [
    "# Sample sentence\n",
    "sentences = [\"Do you take any supplements or medications?\",\n",
    "             \"How are you feeling?\",\n",
    "             \"You should do jumping jacks for the pain.\"]\n",
    "\n",
    "\n",
    "test = \"Are you on any blood thinning medications?\"\n",
    "print('Test sentence:',test)\n",
    "test_vec = model.encode([test])[0]\n",
    "\n",
    "\n",
    "for sent in sentences:\n",
    "    similarity_score = 1-distance.cosine(test_vec, model.encode([sent])[0])\n",
    "    print(f'\\n{sent}\\nSimilarity Score = {similarity_score} ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cc-venv)",
   "language": "python",
   "name": "cc-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
